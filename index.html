<meta charset="utf-8" emacsmode="-*- markdown -*-" />
<link href="https://fonts.googleapis.com/css?family=Lato" rel="stylesheet" />
<link rel="stylesheet" href="./static/fontawesome.all.min.css" />
<script defer src="./static/fontawesome.all.min.js"></script>
<style>
  body {
    font-family: "Lato";
    text-align: left;
    margin: auto;
    max-width: 95%;
    color: #555;
    font-size: 13pt;
    padding-right: 20px;
    overflow-x: hidden;
    text-overflow: ellipses;
  }

  /* no numbering of headings */
  h1:before,
  h2:before,
  h3:before,
  h4:before,
  h5:before,
  h6:before {
    content: none;
  }

  .longTOC a {
    color: #000;
  }

  .tocHeader,
  .tocNumber {
    display: none;
  }

  a,
  div.title,
  contents,
  .tocHeader,
  h1,
  h2,
  h3,
  h4,
  h5,
  h6,
  .nonumberh1,
  .nonumberh2,
  .nonumberh3,
  .nonumberh4,
  .nonumberh5,
  .nonumberh6,
  .shortTOC,
  .mediumTOC,
  .longTOC {
    font-family: inherit;
  }

  div.title,
  h1,
  h2,
  h3,
  h4 {
    font-family: "Lato";
  }

  h1,
  h2,
  h3,
  h4,
  h5,
  h6 {
    color: #555;
    border-color: inherit;
    text-align: center;
    padding-top: 0.5em;
  }

  h2,
  h3,
  h4 {
    border: none;
  }

  .tocTop {
    display: inline;
  }

  div.title,
  div.subtitle {
    text-align: left;
  }

  div.title {
    position: absolute;
    top: -14px;
    left: -200px;
    right: 0px;
    font-weight: 900;
    padding-left: 10px;
    padding-top: 20px;
    padding-bottom: 20px;
    text-shadow: 0px 0px 3px #00c8c8;
    background-color: #00c8c8;
    background-image: url("https://casual-effects.com/markdeep/website-banner.png");
    background-repeat: no-repeat;
    background-position: top right;
    background-size: contain;
    color: #fff;
    font-size: 45px;
    z-index: 10;
  }

  div.afterTitles {
    height: 90px;
  }

  a {
    color: #38a;
    text-decoration: none;
  }

  .authors {
    text-align: center;
  }

  .links {
    text-align: center;
    margin: 20px 0;
  }

  .links a {
    font-size: 17pt;
    margin: 0 8pt;
  }

  .links a > * {
    margin: 0 3pt;
  }

  .abstract {
    padding-top: 20px;
    max-width: 60em;
    width: 80%;
    margin: 3ex auto;
  }

  .teaser {
    margin: 3ex auto;
    text-align: center;
    max-width: 80em;
  }
</style>
<body>
  <div>
    <h1>Accelerating Goal-Conditioned Reinforcement Learning Algorithms and Research</h1>
  </div>
  <div class="authors">
    <a href="https://x.com/m_bortkiewicz">Michał Bortkiewicz</a>, <a href="">Władysław Pałucki</a>,
    <a href="https://x.com/vivek_myers">Vivek Myers</a>, <a href="">Tadeusz Dziarmaga</a>,
    <a href="">Tomasz Arczewski</a>, <a href="https://x.com/LukeKucinski">Łukasz Kuciński</a>,
    <a href="https://ben-eysenbach.github.io/">Benjamin Eysenbach</a>
  </div>

  <p class="links">
    <a href="https://github.com/MichalBortkiewicz/JaxGCRL"><i class="fas fa-code"></i>Code</a>
    <a href="https://arxiv.org/abs/2408.11052"><i class="fas fa-file-alt"></i>Paper</a>
  </p>

  <!-- ![Watch the intro video!](https://www.youtube.com/watch?v=woUgWmXsbxE) -->

  <div class="teaser">
    <img src="imgs/teaser.svg" alt="Teaser Image" width="80%" />
  </div>

  <div class="abstract">
    <p>
      <b>Abstract:</b> Self-supervision has the potential to transform reinforcement learning (RL), paralleling the
      breakthroughs it has enabled in other areas of machine learning. While self-supervised learning in other domains
      aims to find patterns in a fixed dataset, self-supervised goal-conditioned reinforcement learning (GCRL) agents
      discover new behaviors by learning from the goals achieved during unstructured interaction with the environment.
      However, these methods have failed to see similar success, both due to a lack of data from slow environments as
      well as a lack of stable algorithms. We take a step toward addressing both of these issues by releasing a
      high-performance codebase and benchmark JaxGCRL for self-supervised GCRL, enabling researchers to train agents for
      millions of environment steps in minutes on a single GPU. The key to this performance is a combination of
      GPU-accelerated environments and a stable, batched version of the contrastive reinforcement learning algorithm,
      based on an infoNCE objective, that effectively makes use of this increased data throughput. With this approach,
      we provide a foundation for future research in self-supervised GCRL, enabling researchers to quickly iterate on
      new ideas and evaluate them in a diverse set of challenging environments.
    </p>
  </div>
</body>

<!-- <!-1- Markdeep: -1-><style class="fallback"> -->
<!--   body { -->
<!--     visibility: hidden; -->
<!--     white-space: pre; -->
<!--     font-family: monospace; -->
<!--   }</style -->
<!-- ><script src="markdeep.min.js" charset="utf-8"></script -->
<!-- ><script src="https://morgan3d.github.io/markdeep/latest/markdeep.min.js" charset="utf-8"></script -->
<!-- ><script> -->
<!--   window.alreadyProcessedMarkdeep || (document.body.style.visibility = "visible") -->
<!-- </script> -->
